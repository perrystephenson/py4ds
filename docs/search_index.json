[
["index.html", "Python for Data Science 1 Introduction 1.1 What is Python? 1.2 Setting up Python 1.3 Getting Help", " Python for Data Science Perry Stephenson 2018-11-04 1 Introduction This book has a target audience of one person: myself. I’m writing it as a reference for myself as I learn Python and start to transition from being 100% R to more of a 50/50 language mix. I’m making it public for two reasons: It’s easier for me to access my notes from anywhere without a password It might be useful for someone else who’s trying to figure out how to do something in Python It’s eventually going to resemble an opinionated manual, where I thoroughly document the bits of the language that I think are worth using, and completely ignore the bits I don’t use. This may or may not be useful for other people! It’s also going to make a lot of comparisons between R and Python, for my benefit. 1.1 What is Python? Python is a language. IPython is an interactive shell (which is itself tautologous, as all shells are interactive, surely?). Python is the name of the language, and there are multiple implementations of Python, including CPython (the reference implementation), PyPy (a faster implemenetation), and more. This is different to R, which is both a language AND an implementation, meaning that the R language is defined by the behaviour of the R interpreter. R runs in both script mode and interactive mode, which is again a key difference. So Python is to R as IPython is to R as CPython is to R. Easy! 1.2 Setting up Python This is a Python book written in R Markdown. This means that all of the Python examples are being excuted via the reticulate package. The Python distribution for all of these examples is Anaconda Python (version 3.6), and the packages are being managed within a conda environment. I decided to use Conda to manage my Python environment based on the discussion in this blog post and to make sure that I had full control over the environment. To set up a new Macbook (MacOS Mojave) with Python, I: Visited https://www.anaconda.com/download/#macos in a web browser and downloaded the Python 3.6 installer, then installed it. Created a new conda environment for this project (conda create --name py4ds python=3.6) Installed numpy, pandas and matplotlib into the conda environment using conda activate py4ds then conda install numpy pandas matplotlib Configured reticulate to use the new environment (and load a package to force it to load this non-default environment) # R library(reticulate) use_condaenv(condaenv = &#39;py4ds&#39;, require = TRUE, conda = &#39;/Users/perrystephenson/anaconda3/bin/conda&#39;) import(&#39;pandas&#39;) ## Module(pandas) Now we can check that the correct version of Python is being used: # Python import sys print(sys.version) ## 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:10:00) ## [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] And to make sure everything is working properly, I’ll generate a plot with matplotlib. # Python import matplotlib.pyplot as plt plt.plot([0, 2, 1, 4]) plt.show() 1.3 Getting Help Getting help about a Python function is pretty easy, using the help(&lt;thing&gt;) syntax (for example help(len)). The documentation seems a bit sparse, so I suspect that Google is also a pretty good place to go when looking for help on a function or a feature. "],
["syntax.html", "2 Base Syntax 2.1 Types 2.2 Comments 2.3 Basic Operations 2.4 Strings 2.5 Type Casting 2.6 Lists / Arrays / Columns / Vectors 2.7 Indexing 2.8 Copy / Modify 2.9 Grouping 2.10 Missing values and extreme numbers 2.11 Booleans 2.12 Dictionaries 2.13 Functions 2.14 Methods 2.15 Namespaces", " 2 Base Syntax This chapter will cover the basics of Base Python, that is the syntax of the Python Interpreter without any non-bundled packages. Note Python does not automatically print the result of expressions. They must always be wrapped in a print() function call if you want them to be printed to the standard output. 2.1 Types Python is “dynamically typed” which means that it can automatically infer the types of variables, and these types can change throughout the course of your script. This is similar to R, but very different to C. To see the type of an object in Python, use type(var). x = 0.5 print(type(x)) ## &lt;class &#39;float&#39;&gt; 2.2 Comments Comments start with the hash #, just like in R and Bash. You can also use docstrings as the first statement inside a function - this is written like a multi-line comment which becomes the documentation for the function. # This is a comment &quot;&quot;&quot;This is a multi-line docstring &quot;&quot;&quot; 2.3 Basic Operations The standard operators are pretty straightforward (*, /, +, -), exponentiation is ** (i.e. 4**2) instead of ^. Assignment is = and function arguments are also passed via =. Equality tests use ==. print(2**2 == 4) ## True print(2 == 3) ## False 2.4 Strings Python accepts both single ' and double &quot; quotes. You can concatenate strings using the + operator - cool! Python does not automatically cast between strings and other types (booooooo) which means you have to cast it explicitly when you want to build error messages, turn strings into numeric types, etc. x = 0.75 msg = &#39;The value of x is &#39; + str(x) print(msg) ## The value of x is 0.75 2.5 Type Casting Python uses sensibly named functions to cast between different types, and does not do this automatically. For example, print('Hello number ' + 3) will not work, as you need to explicitly cast like this: print('Hello number ' + str(3)). The casting functions are named after the data types: int str float bool etc 2.6 Lists / Arrays / Columns / Vectors In R, if you define something using the inline notation c(1.73, 1.68, 1.71, 1.89) then you are creating an “atomic vector” (i.e. a vector containing only one type of data). In Python, if you define something using the inline notation [1.73, 1.68, 1.71, 1.89] then are creating a “list”. “List” seems to have the same meaning as R (can contain multiple types, can contain other lists, etc), so it is just the notation that differs. There is no base equivalent to the atomic vector in Python - it seems that this functionality is provided by the NumPy Array. my_list = [&#39;1&#39;, 2, 3.0, &#39;d&#39;] print(my_list) ## [&#39;1&#39;, 2, 3.0, &#39;d&#39;] You can also put lists inside lists: my_nested_list = [[&quot;Hello&quot;, 1],[&quot;World&quot;, 2]] print(my_nested_list) ## [[&#39;Hello&#39;, 1], [&#39;World&#39;, 2]] 2.7 Indexing Python uses 0-based indexing, whereas R uses 1-based indexing. If you want to select the 4th element in a vector, you would use index 4 in R (1,2,3,4), but index 3 in Python (0,1,2,3). The syntax for this in Python is the same as R - var[3]. Negative indices work very differently! In R, a negative index will return the vector with the specified item removed i.e. if you use var[-3] then you will get the vector without the third element. In Python however, it will select a single element by counting backwards. An index of -1 returns the final element (because you start at index zero and take one step backwards), -2 returns the second last element, and so on. Slicing works even more strangely in Python. Whilst in R, using index var[3:5] will return the 3rd, 4th and 5th elements, in Python this will only return the 4th and 5th elements. This is because the syntax in Python is [inclusive:exclusive] and because of 0-based indexing. One nice shortcut in Python (not present in R) is the [:n] and [n:] syntax. In the first case, the blank argument to the infix operator : is interpreted as a 0, and in the second case the blank argument is interpreted as the length of the vector (so that it will select the rest of the vector). Python lists can be joined using the + operator. example = [0,1,2] + [3,4] print(example) ## [0, 1, 2, 3, 4] Deleting elements is a bit different - you need to use del(var[3]) to remove an element from the list. del(example[3]) print(example) ## [0, 1, 2, 4] 2.8 Copy / Modify R has a nice “copy on modify” behaviour, which means that when you assign a list (or anything else) to a new variable, it doesn’t copy it until you make a change, at which point it saves a modified copy of that object. In Python however, the behaviour is different for different data types (booooooo). Lists, for example, are copied by reference, which means that changing an element in a “copied” list also changes the same element in the original list. To get around this you need to do something like y = list(x) or y = x[:] to explicitly copy all items from the list. x = [1,2,3,4] y = x y[2] = 5 print(x) ## [1, 2, 5, 4] x = [1,2,3,4] y = list(x); y[2] = 5 z = x[:]; z[2] = 5 print(x) ## [1, 2, 3, 4] 2.9 Grouping Python does not use braces - it uses indentation to group blocks of code. This is supposed to improve readability, but in practice it can be super messy. Can use spaces or tabs. if condition : execute this and this because we&#39;re still indented execute this regardless because we&#39;ve got no indent 2.10 Missing values and extreme numbers In R, you have NA (missing) and NULL (undefined, empty), NaN (not a number), and Inf (infinity). In Python, you have None, and numpy has numpy.nan (not a number). There is no equivalent to Inf, as it just raises an error. 2.11 Booleans In R, booleans are defined as TRUE and FALSE, with the shortcut T and F also commonly used. In Python, the booleans are simply defined as True and False. Boolean arithmetic is performed using the and and or keywords, corresponding to the &amp; and | operators in R. You can also use the not operator, which corresponds to ! in R. Booleans are a bit harder to work with when you’re using numpy arrays, because the base logic keywords are not vectorised. To work with numpy arrays, you have to use the built in numpy functions: np.logical_and() np.locical_or() np.locical_not() 2.12 Dictionaries Dictionaries don’t really exist in R, because the dictionary functionality (named elements) is available in both atomic vectors and lists. To create a dictionary in Python, you can use the following syntax: world = {&quot;afghanistan&quot;:30.55, &quot;albania&quot;:2.77, &quot;algeria&quot;:39.21} You can also do nested dictionaries - the keys are somewhat limited (they can be any immutable data type) but the values can be dictionaries if you want. You can retrieve the keys from a dictionary using the .keys() method, e.g. world.keys(). You can select elements from a dictionary using the key inside square brackets, e.g. world['albania'] print(world.keys()) ## dict_keys([&#39;afghanistan&#39;, &#39;albania&#39;, &#39;algeria&#39;]) print(world[&#39;albania&#39;]) ## 2.77 In many ways, dictionaries are like named lists in R. You can add elements to a dictionary using world['italy'] = 59.83 for example. You can also interrogate whether a key exists in a dictionary using the in operator, which is like the %in% operator from R. For example: print(&#39;albania&#39; in world) ## True print(&#39;moon&#39; in world) ## False 2.13 Functions Functions are defined using the keyword def, like so: def repeat(s, exclaim): &quot;&quot;&quot; Returns the string &#39;s&#39; repeated 3 times. If exclaim is true, add exclamation marks. &quot;&quot;&quot; result = s + s + s if exclaim: result = result + &#39;!!!&#39; return result print(repeat(&#39;ha&#39;, exclaim = True)) ## hahaha!!! A return statement appears to be compulsory in Python functions, unlike in R where it is not strictly required. Like in all other scripting languages, functions must be defined before they are used (i.e. earlier in the script). Importing modules is probably a sensible way to manage this. Function arguments look to be specified and evaluated similarly to R - you name the arguments and you can give them default values in the definition statement. When using the function you can resolve arguments by name or by order (but you cannot mix the two approaches), and there is no partial matching. 2.13.1 Lambda functions These are just like anonymous functions in R - you can define them inline and don’t necessarily need to provide a name. Useful to save typing, but also useful in the map() and functools.reduce() functions. my_glue_function = lambda a, b: a + &#39; &#39; + b + &quot;!&quot; print(my_glue_function(&quot;Hello&quot;, &quot;World&quot;)) ## Hello World! 2.14 Methods Python is a proper object-oriented (OO) language, unlike R which is a functional language with three different OO systems built on top of it. The Python model for objects and methods is most similar to R’s Reference Classes (RC) framework. In Python, methods belong to objects (you invoke them using object.method() notation), and behave according to the type of the object. Some methods can mutate the object they belong to, others do not, and there is no easy way to tell the difference without reading the documentation. 2.15 Namespaces If you have a module called binky.py and a function in that module called foo() then the fully qualified function name is binky.foo(). This is sort of like R’s :: notation (e.g. dplyr::select()) except that Python modules seem to typically be more light weight than R packages. "],
["importing-and-exporting.html", "3 Importing and Exporting 3.1 Opening Text Files 3.2 Relational Databases 3.3 Exotic Filetypes 3.4 Working with the file system 3.5 Retrieving files from the web 3.6 Parsing HTML 3.7 Working with JSON 3.8 Working with APIs", " 3 Importing and Exporting 3.1 Opening Text Files 3.1.1 Plain Text These are the easiest files to open. file = open(&#39;huck_finn.txt&#39;, mode=&#39;r&#39;) # &#39;r&#39; is to read text = file.read() file.close() The .read() method reads the entire file. You can also use .readline() which reads a line at a time. You can also manage files using a “context manager”: with open(&#39;huck_finn.txt&#39;, mode=&#39;r&#39;) as file : print(file.read()) This has the advantage that it doesn’t require you to close the connection at the end of the script. 3.1.2 Tabular Data 3.1.2.1 NumPy arrays import numpy as np data = np.loadtxt(&#39;MNIST.txt&#39;, delimiter=&#39;,&#39;) Some additional useful arguments include: skiprows - set to an integer (typically 1) to skip header rows usecols - pass a list of integers (e.g. usecols=[0,2]) to select specified columns dtype - numpy arrays must all be a single data type, so this lets you cast everything to a type (for example dtype=str) You can also load data with multiple data types using np.genfromtxt(), and if you pass the dtype=None argument then it will automatically detect column types for you. data = np.genfromtxt(&#39;titanic.csv&#39;, delimiter=&#39;,&#39;, names=True, dtype=None) When you do this, the result is a structured array rather than a 2d numpy array. This isn’t ideal, which is why pandas exists. Also note that the function np.recfromcsv() does the same as np.genfromtxt() except that it sets dtype=None, delimiter=',' and names=True by default - handy! 3.1.2.2 Pandas DataFrames These are the standard for almost all data work in Python. The Pandas chapter will include more information about how to work with DataFrames in Pandas. import pandas as pd data = pd.read_csv(&#39;winequality-red.csv&#39;) Key options include: sep - delimiter character nrows - specify the number of rows to read header - set to None (not 0!) if your data doesn’t have a header row na_values - strings to treat as missing values Pandas has some handy helpers, including: .head() - shows the top 5 rows `.values - returns a numpy array 3.2 Relational Databases 3.2.1 Using SQLAlchemy from sqlalchemy import create_engine engine = create_engine(&#39;sqlite:///Northwind.sqlite&#39;) You can retrieve the table names from the database using the .table_names() method of the engine object. To query the database using the engine: con = engine.connect() rs = con.execute(&#39;select * from Album&#39;) df = pd.DataFrame(rs.fetchall()) df.columns = rs.keys() con.close() You can also do this using a context manager: with engine.connect() as con: rs = con.execute(&#39;select LastName, Title from Employee&#39;) df = pd.DataFrame(rs.fetchmany(size = 3)) df.columns = rs.keys() You can also use this engine directly with Pandas: df = pd.read_sql_query(‘select * from Orders’, engine) 3.3 Exotic Filetypes 3.3.1 Excel import pandas as pd data = pd.ExcelFile(&#39;urbanpop.xlsx&#39;) print(data.sheet_names) df1 = data.parse(&#39;1960-1966&#39;) # sheet name as string, or index as float Key options include: skiprows - indexes of rows to skip - must be a list (zero indexed!) names - can be used to provide (or override) the row names parse_cols - can be used to specify which columns to import 3.3.2 Pickle (serialised) import pickle with open(&#39;data.pkl&#39;, &#39;rb&#39;) as file: d = pickle.load(file) 3.3.3 HDF5 HDF5 stands for Hierarchical Data Format 5. It’s the standard for storing large quantities of numerical data, and can scale to exabytes. import h5py data = h5py.File(&#39;LIGO_data.hdf5&#39;, &#39;r&#39;) # &#39;r&#39; is to read The file can look like a dict, and you can explore it using the same techniques: for key in data.keys() : print(key) Because it is hierarchical, you can drill down further to find out what is there: for key in data[&#39;meta&#39;].keys() : print(key) You can grab values using the .value attribute: strain = data[&#39;strain&#39;][&#39;Strain&#39;].value 3.4 Working with the file system You can programmatically interrogate the file system using the os package. import os wd = os.getcwd() os.listdir(wd) You can also use the glob package to find files from the file system: # Import necessary modules import pandas as pd import glob # Write the pattern: pattern pattern = &#39;*.csv&#39; # Save all file matches: csv_files csv_files = glob.glob(pattern) # Print the file names print(csv_files) # Load the second file into a DataFrame: csv2 csv2 = pd.read_csv(csv_files[1]) # Print the head of csv2 print(csv2.head()) 3.5 Retrieving files from the web from urllib.request import urlretrieve url = &#39;https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39; dat = urlretrieve(url, “winequality-red.csv”) Pandas can also do this for you without saving the intermediate file. This works with all of the Pandas functions including read_csv and read_excel df = pd.read_csv(url, sep = &#39;;&#39;) 3.5.1 Working with HTTP requests directly from urllib.request import urlopen, Request url = &quot;http://www.datacamp.com/teach/documentation&quot; request = Request(url) response = urlopen(request) print(type(response)) html = response.read() response.close() 3.5.2 Using the requests package The requests package is the equivalent of R’s httr package, and is the most popular Python package for working with HTTP requests. # Import package import requests # Specify the url: url url = &quot;http://www.datacamp.com/teach/documentation&quot; # Packages the request, send the request and catch the response: r r = requests.get(url) # Extract the response: text text = r.text # Print the html print(text) 3.6 Parsing HTML You can parse HTML using the BeautifulSoup package. # Import packages import requests from bs4 import BeautifulSoup # Specify url: url url = &#39;https://www.python.org/~guido/&#39; # Package the request, send the request and catch the response: r r = requests.get(url) # Extracts the response as html: html_doc html_doc = r.text # Create a BeautifulSoup object from the HTML: soup soup = BeautifulSoup(html_doc) # Prettify the BeautifulSoup object: pretty_soup pretty_soup = soup.prettify() # Print the response print(pretty_soup) You can also parse the tag tree with the BeautifulSoup object # Get the title of Guido&#39;s webpage: guido_title guido_title = soup.title # Print the title of Guido&#39;s webpage to the shell print(guido_title) # Get Guido&#39;s text: guido_text guido_text = soup.get_text() # Print Guido&#39;s text to the shell print(guido_text) # Find all &#39;a&#39; tags (which define hyperlinks): a_tags a_tags = soup.find_all(&#39;a&#39;) # Print the URLs to the shell for link in a_tags: print(link.get(&#39;href&#39;)) 3.7 Working with JSON import json # Load JSON: json_data with open(&quot;a_movie.json&quot;) as json_file: json_data = json.load(json_file) # Print each key-value pair in json_data for k in json_data.keys(): print(k + &#39;: &#39;, json_data[k]) 3.8 Working with APIs You can query APIs directly with the requests package # Import requests package import requests # Assign URL to variable: url url = &#39;http://www.omdbapi.com/?apikey=ff21610b&amp;t=the+social+network&#39; # Package the request, send the request and catch the response: r r = requests.get(url) # Print the text of the response print(r.text) You can pull out the JSON directly from the object using the .json() method: # Decode the JSON data into a dictionary: json_data json_data = r.json() # Print each key-value pair in json_data for k in json_data.keys(): print(k + &#39;: &#39;, json_data[k]) You can parse multiple levels of nested JSON easily: json_data[&#39;query&#39;][&#39;pages&#39;][&#39;24768&#39;][&#39;extract&#39;] "],
["control-flow.html", "4 Control Flow 4.1 If statements 4.2 While loop 4.3 For loop 4.4 Error Handling 4.5 Iterators and Iterables 4.6 List Comprehensions 4.7 Generators", " 4 Control Flow Bottom line up front, Python is weird about groupings. Instead of using braces and making things clear and explicit, Python enforces indentation as a way of grouping code. What this means if you have both spaces and tabs is unclear, but it’s certainly going to get confusing. Add to this Python’s mixed bag when it comes to putting function arguments in brackets and we’ve got a real mess. 4.1 If statements The general syntax for an if statement is: if condition : execute this and this because we&#39;re still indented execute this regardless because we&#39;ve got no indent The general syntax for an if else statement is: if condition : execute this else : execute this The general syntax for an else if statement is: if condition : execute this elif condition : execute this else : execute this 4.2 While loop The general syntax for a while loop is: while condition : expression 4.3 For loop The general syntax for a for loop is: for var in seq : expression You can also do inline enumeration if you want to (to get access to the index as well as the value), but it’s a bit flimsy and hard to understand because it only exists in the for loop syntax (so you can’t easily debug how it works): for index, var in enumerate(seq): expression You can also iterate along multiple columns in nested lists: for room, area in house : expression To iterate through the rows of a pandas DataFrame, you can use the following: for lab, row in df.iterrows() : print(lab) # The row label print(row) # The pandas Series, i.e. a named list consisting of the row elements To iterate through key:value pairs in a dictionary, use: for key, val in dict.items() : print(key) # The key print(val) # The value 4.4 Error Handling Error handling in Python seems to be based on the try-except model. You can use this to control execution flow conditional on the type of error raised, and you can raise your own errors using the raise keyword. def sqrt(x) : &quot;&quot;&quot;Returns the square root of a number.&quot;&quot;&quot; try: if x &lt; 0 : raise ValueError(&#39;x must be non-negative&#39;) return x ** 0.5 except TypeError: # This section will execute if there is a TypeError print(&#39;x must be an int or a float&#39;) print(sqrt(4)) ## 2.0 print(sqrt(&#39;4&#39;)) ## x must be an int or a float ## None print(sqrt(-4)) ## ValueError: x must be non-negative ## ## Detailed traceback: ## File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt; ## File &quot;&lt;string&gt;&quot;, line 5, in sqrt Amongst all the printout, you can see that this has indeed raised a ValueError with the error message specified. 4.5 Iterators and Iterables Examples include lists, strings, dictionaries, file connections They need to have an iter() method Applying iter() to an iterable creates an iterator Iterators need to have a next() method word = &quot;Dog&quot; it = iter(word) print(next(it)) ## D print(next(it)) ## o print(next(it)) ## g print(next(it)) ## StopIteration: ## ## Detailed traceback: ## File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt; You can also use the “splat” operator to get all remaining elements. word = &quot;Hello&quot; it = iter(word) print(next(it)) ## H print(*it) ## e l l o 4.5.1 Enumerate The enumerate() function can be used to return an iterator which gives two values, the index and the value of the underlying iterable. words = [&quot;Hello&quot;, &quot;World&quot;, &quot;!!!&quot;] for i, x in enumerate(words) : print(i, x) ## 0 Hello ## 1 World ## 2 !!! 4.5.2 Zip The zip() function can be used to take two or more lists and “zip” them together into a single iterable. list1 = [0,1,2,3]; list2 = [10,11,12,13]; list3 = [20,21,22,23] for a, b, c in zip(list1, list2, list3) : print(a, b, c) ## 0 10 20 ## 1 11 21 ## 2 12 22 ## 3 13 23 You can also use the zip() function to unzip, by using the splat operator. tuple1 = (0,1,2,3); tuple2 = (10,11,12,13); z = zip(tuple1, tuple2) result1, result2 = zip(*z) print(result1 == tuple1) ## True print(result2 == tuple2) ## True 4.6 List Comprehensions List comprehensions collapse for loops for building lists into a single line. You can write a list comprehension over any iterable. The general structure is: &lt;result&gt; = [&lt;output expression&gt; for &lt;iterator variable&gt; in &lt;iterable&gt;] Some examples: nums = [12, 8, 21, 3, 16] new_nums = [num + 1 for num in nums] print(new_nums) ## [13, 9, 22, 4, 17] result = [num for num in range(11)] print(result) ## [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] You can also use nested comprehensions by chaining multiple for statements together, but it starts to get a bit ugly. pairs = [(num1, num2) for num1 in range (0,2) for num2 in range (6,8)] print(pairs) ## [(0, 6), (0, 7), (1, 6), (1, 7)] You can also use conditionals within list comprehensions. The general syntax is: &lt;result&gt; = [&lt;output&gt; for &lt;ivar&gt; in &lt;iterable&gt; if &lt;condition&gt;] For example, to make a list of the squares of only even numbers, you could use: print([num ** 2 for num in range(10) if num % 2 == 0]) ## [0, 4, 16, 36, 64] You can also use conditionals on the output expression, with the general syntax &lt;result&gt; = [&lt;true output&gt; if &lt;condition&gt; else &lt;false output&gt; for &lt;ivar&gt; in &lt;iterable&gt;] For example, to square even numbers but not square odd numbers, you could use: print([num ** 2 if num % 2 == 0 else num for num in range(10)]) ## [0, 1, 4, 3, 16, 5, 36, 7, 64, 9] You can also create dictionary comprehensions using the same syntax. # Create a list of strings: fellowship fellowship = [&#39;frodo&#39;, &#39;samwise&#39;, &#39;merry&#39;, &#39;aragorn&#39;, &#39;legolas&#39;, &#39;boromir&#39;, &#39;gimli&#39;] # Create dict comprehension: new_fellowship new_fellowship = {member:len(member) for member in fellowship} # Print the new list print(new_fellowship) ## {&#39;frodo&#39;: 5, &#39;samwise&#39;: 7, &#39;merry&#39;: 5, &#39;aragorn&#39;: 7, &#39;legolas&#39;: 7, &#39;boromir&#39;: 7, &#39;gimli&#39;: 5} 4.7 Generators A generator is like a list comprehension, except that it does not store the list in memory. You can create a generator by replacing [] with () in any list comprehension statement. It behaves like any other iterator, except that the value is lazily evaluated - i.e. the elements of the sequence are only calculated at the time they’re needed. As a trivial example of why this could be useful, the following code will cause my Python session to crash: [num for num in range(10**1000000)] But I can comfortably create a generator which I can use as an iterable: it = (num for num in range(10**1000000)) print(it) ## &lt;generator object &lt;genexpr&gt; at 0x123aff518&gt; You can also write generator functions which can include any arbitrary code. The only difference between normal functions and generator functions is that instead of using return to return all objects at once, a generator function will use yield multiple times throughout the execution of the function. When the generator function is iterated over, the function will run through the code until it hits yield, then it will return that value to the called (which most likely called next() on the iterator), and then pause execution. The next time next() is called, it will yield the next value, and so on until the generator function is exhausted (when the function finishes). def num_sequence(n) : i = 0 while i &lt; n : yield i i += 1 it = num_sequence(3) print(next(it)) ## 0 print(next(it)) ## 1 print(next(it)) ## 2 for num in num_sequence(3) : print(num) ## 0 ## 1 ## 2 "],
["scripting.html", "5 Scripting 5.1 Imports 5.2 Boilerplate", " 5 Scripting 5.1 Imports If you import a module using import sys, then you make the functions from sys available in your code using their fully qualified function names, e.g. sys.argv and sys.exit(). This is different to R, where using the library() function makes functions available using their short names, e.g. after calling library(dplyr) you can just call select(). To get this sort of behaviour in Python, some people use from sys import argv, exit which makes specified functions available using their short names. In general though, it makes sense to use fully qualified names unless they’re really long, in the same way that it makes sense to use functions in R using the :: notation. To save you a bit of typing, you can rename the imported packages using the import &lt;package&gt; as &lt;shortcut&gt; syntax, e.g. import numpy as np. Going further, you can even do things like from numpy import array as np_array to import specific functions and rename them all in one step. Python has a “standard library” of imports available, just like R. Some examples include sys, re and os. You can also import constants from packages - e.g. math.pi. Some important imports include: numpy, matplotlib, pandas. 5.2 Boilerplate #!/usr/bin/env python import sys def main(): print(&#39;Hello there&#39;, sys.argv[1]) if __name__ == &#39;__main__&#39;: main() In this example: the shebang will use the correct Python conda environment (based on whichever conda env is active when the script is executed) the package imports are included at the top of the file the main() function is the part of the code that should run when you execute the script from the command line The strange thing at the end calls the main() function "],
["numpy-numeric-python.html", "6 Numpy (Numeric Python) 6.1 Numpy arrays 6.2 Two dimensional numpy arrays", " 6 Numpy (Numeric Python) This is a package which provides some types and functions for maths. The key use of numpy is the numpy.array() function, which provides something similar to the c() function (atomic vector) in R. Unlike lists (in both R and Python), the numpy.array() function allows vectorised operations. By convention, numpy is normally imported as np. import numpy as np 6.1 Numpy arrays To create a numpy array: import numpy as np temp = np.array([1,2,3,4]) print(temp) ## [1 2 3 4] Note the strange bracket nesting - it looks like the array function takes a list as an argument, which means you need to use the square brackets to make a list, then pass this list as the argument to the array function. One dimensional numpy arrays are useful for R users, because they behave like atomic vectors in R; in fact numpy arrays are also atomic - they can only hold items with the same data type. 6.2 Two dimensional numpy arrays You can define n-dimensional numpy arrays using lists of lists. The highest level of the hierarchy is the first dimension of the n-dimensional array, the second level is the second dimension of the array, and so on. When working with a two dimensional array, this means that you can create a 2 row, 5 column numpy array using the following command: import numpy as np np_2d = np.array([[1, 2, 3, 4, 5 ], [6, 7, 8, 9, 10]]) print(np_2d) ## [[ 1 2 3 4 5] ## [ 6 7 8 9 10]] To interrogate the properties of the array you can use methods. For example, you can get the dimensions of the array using np_2d.shape - this would be written as dim(np_2d) in R. print(np_2d.shape) ## (2, 5) "],
["pandas.html", "7 Pandas 7.1 Creation 7.2 Subsetting 7.3 Reading in chunks 7.4 Working with DataFrames", " 7 Pandas The pandas package was written by Wes McKinney (who seems to be Hadley Wickham’s counterpart for Python) and builds on top of the numpy package to provide DataFrames. 7.1 Creation To create a DataFrame manually: import pandas as pd mydict = { &quot;country&quot;: [&#39;Brazil&#39;, &#39;Russia&#39;, &#39;India&#39;, &#39;China&#39;, &#39;South Africa&#39;], &quot;capital&quot;: [&#39;Brasilia&#39;, &#39;Moscow&#39;, &#39;New Delhi&#39;, &#39;Beijing&#39;, &#39;Pretoria&#39; ], &quot;area&quot;: [ 8.516, 17.10, 3.286, 9.597, 1.221 ], &quot;population&quot;: [ 200.4, 143.5, 1252, 1357, 52.98 ]} df = pd.DataFrame(mydict) df.index = [&#39;BR&#39;, &#39;RU&#39;, &#39;IN&#39;, &#39;CH&#39;, &#39;SA&#39; ] print(df) ## country capital area population ## BR Brazil Brasilia 8.516 200.40 ## RU Russia Moscow 17.100 143.50 ## IN India New Delhi 3.286 1252.00 ## CH China Beijing 9.597 1357.00 ## SA South Africa Pretoria 1.221 52.98 Alternatively, if you have data in a CSV file you can import it using: df = pd.read_csv(&#39;&lt;path&gt;&#39;) # If there are no column names df = pd.read_csv(&#39;&lt;path&gt;&#39;, index_col = 0) # If there are column names You can also create a DataFrame as a list of lists: import pandas as pd cities = [&#39;Austin&#39;, &#39;Dallas&#39;, &#39;Austin&#39;, &#39;Dallas&#39;] signups = [7, 12, 3, 5] visitors = [139, 237, 326, 456] weekdays = [&#39;Sun&#39;, &#39;Sun&#39;, &#39;Mon&#39;, &#39;Mon&#39;] list_labels = [&#39;city&#39;, &#39;signups&#39;, &#39;visitors&#39;, &#39;weekday&#39;] list_cols = [cities, signups, visitors, weekdays] zipped = list(zip(list_labels, list_cols)) data = dict(zipped) users = pd.DataFrame(data) print(users) ## city signups visitors weekday ## 0 Austin 7 139 Sun ## 1 Dallas 12 237 Sun ## 2 Austin 3 326 Mon ## 3 Dallas 5 456 Mon 7.2 Subsetting To select a column in pandas, use df['country']. This returns a “pandas Series” object, which is like a 1D element of a data frame. If you want to get a data frame back instead of a series, use df[['country']]. This is the opposite of R, where the [[]] is used to drill down further than []. The reason for this is that [] defines a list in Python, so you’re really calling df[&lt;subset&gt;] where &lt;subset&gt; is a list of length 1. In R, the [[]] subset operator is actually a function, hence the differing behaviours. This means that subsetting for multiple columns in Python doesn’t take too much writing: df[['country', 'capital']]. Interestingly, and perhaps confusingly, if you provide a slice (range) to df[] then you will be subsetting on rows, not columns! Using df[1:4] selects the 2nd through 4th rows of the data frame. If you want to do anything more complex than this, it starts getting a bit weird, and you have to use the loc() method (which stands for “location”). To pull out a named row, you need to use the df.loc['RU'] syntax (which returns a Series object), or df.loc[['RU']] (which returns a DataFrame). You can also select multiple rows this way: df.loc[['RU', 'IN', 'CH']]. You can then extend this to subset on columns as well, which starts to look a bit more like R (and like the 2D numpy array): df.loc[['RU', 'IN', 'CH'], ['country', 'capital']]. If you want to use an index, then you can do the same thing with lists of integers passed to the iloc() method (which stands for index-location). It seems like you probably need to chain these functions together if you want to have a mix of subsetting approaches. 7.3 Reading in chunks You can use the chunksize argument to read a CSV file in chunks, then iterate over the chunks in a loop. This can be useful when you’re dealing with large amounts of data that won’t fit in memory. import pandas as pd result = [] for chunk in pd.read_csv(&#39;data.csv&#39;, chunksize = 1000) : result.append(sun(chunk[&#39;x&#39;])) total = sum(result) print(total) 7.4 Working with DataFrames 7.4.1 Basics You can print the head or tail of a DataFrame using .head() and .tail() respectively. You can inspect the shape of the DataFrame by accessing the .shape attribute and get the names of the columns using .columns. # Import pandas import pandas as pd # Read the file into a DataFrame: df df = pd.read_csv(&#39;dob_job_application_filings_subset.csv&#39;) # Print the head of df print(df.head()) # Print the tail of df print(df.tail()) # Print the shape of df print(df.shape) # Print the columns of df print(df.columns) The .info() method gives you a summary of the DataFrame. print(df.info()) &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 12846 entries, 0 to 12845 Data columns (total 13 columns): Job # 12846 non-null int64 Doc # 12846 non-null int64 Borough 12846 non-null object Initial Cost 12846 non-null object Total Est. Fee 12846 non-null object Existing Zoning Sqft 12846 non-null int64 Proposed Zoning Sqft 12846 non-null int64 Enlargement SQ Footage 12846 non-null int64 Street Frontage 12846 non-null int64 ExistingNo. of Stories 12846 non-null int64 Proposed No. of Stories 12846 non-null int64 Existing Height 12846 non-null int64 Proposed Height 12846 non-null int64 dtypes: int64(10), object(3) memory usage: 1.3+ MB None For more detailed statistics about numeric columns, you can also use the .describe() method. 7.4.2 Selecting Columns If the column name does not contain any special characters or spaces, and is not the name of a Python function, then you can access columns as attributes. For example, this means that df.continent and df['continent'] are equivalent. 7.4.3 Counting Values You can use the .value_counts() method on a column (AKA Series) to count and sort occurrences of each value in the column. # Print the value counts for &#39;Site Fill&#39; print(df[&#39;State&#39;].value_counts(dropna=False)) Name: State, dtype: int64 NOT APPLICABLE 7806 NaN 4205 ON-SITE 519 OFF-SITE 186 USE UNDER 300 CU.YD 130 7.4.4 Plotting Things Pandas has tight integration with matplotlib which allows you to call plotting methods on columns directly. import pandas as pd import matplotlib.pyplot as plt df.population.plot(&#39;hist&#39;) plt.show() df.boxplot(column = &#39;population&#39;, by = &#39;continent&#39;) plt.show() df.plot(kind=&#39;scatter&#39;, x=&#39;initial_cost&#39;, y=&#39;total_est_fee&#39;, rot=70) plt.show() 7.4.5 Reshaping Data (Tidy Data) The pd.melt() function is functionally similar to the tidyr::gather() function in R in that it takes a “wide” data representation and gathers the columns into a “narrow” representation. From DataCamp: There are two parameters you should be aware of: id_vars and value_vars. The id_vars represent the columns of the data you do not want to melt (i.e., keep it in its current shape), while the value_vars represent the columns you do wish to melt into rows. By default, if no value_vars are provided, all columns not set in the id_vars will be melted. This could save a bit of typing, depending on the number of columns that need to be melted. You can rename the variable column by specifying an argument to the var_name parameter, and the value column by specifying an argument to the value_name parameter. You can then use pd.melt() like this: print(airquality.head()) airquality_melt = pd.melt(airquality, id_vars=[&#39;Month&#39;, &#39;Day&#39;], var_name=&#39;measurement&#39;, value_name=&#39;reading&#39;) print(airquality_melt.head()) Ozone Solar.R Wind Temp Month Day 0 41.0 190.0 7.4 67 5 1 1 36.0 118.0 8.0 72 5 2 2 12.0 149.0 12.6 74 5 3 3 18.0 313.0 11.5 62 5 4 4 NaN NaN 14.3 56 5 5 Month Day measurement reading 0 5 1 Ozone 41.0 1 5 2 Ozone 36.0 2 5 3 Ozone 12.0 3 5 4 Ozone 18.0 4 5 5 Ozone NaN To go the other way, i.e. to “spread” the table (like tidyr::spread() in R) you need to use the .pivot() or .pivot_table() method on the DataFrame object. The main difference between these two methods seems to be that .pivot() cannot deal with duplicate values, where .pivot_table() allows you to pass in an aggregation function to handle duplicates (via the aggfunc argument). .pivot_table() also allows you to pass multiple index columns. print(airquality_melt.head()) airquality_pivot = airquality_melt.pivot(index=[&#39;Month&#39;, &#39;Day&#39;], columns=&#39;measurement&#39;, values=&#39;reading&#39;) print(airquality_pivot.head()) Month Day measurement reading 0 5 1 Ozone 41.0 1 5 2 Ozone 36.0 2 5 3 Ozone 12.0 3 5 4 Ozone 18.0 4 5 5 Ozone NaN measurement Ozone Solar.R Temp Wind Month Day 5 1 41.0 190.0 67.0 7.4 2 36.0 118.0 72.0 8.0 3 12.0 149.0 74.0 12.6 4 18.0 313.0 62.0 11.5 5 NaN NaN 56.0 14.3 Note that this DataFrame looks a bit different, because it has a hierarchical index (AKA MultiIndex) which seems to be how pandas implements grouping. You can remove this by calling the .reset_index() method on the DataFrame. print(airquality_pivot.index) airquality_pivot_reset = airquality_pivot.reset_index() print(airquality_pivot_reset.index) print(airquality_pivot_reset.head()) MultiIndex(levels=[[5, 6, 7, 8, 9], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]], labels=[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]], names=[&#39;Month&#39;, &#39;Day&#39;]) RangeIndex(start=0, stop=153, step=1) measurement Month Day Ozone Solar.R Temp Wind 0 5 1 41.0 190.0 67.0 7.4 1 5 2 36.0 118.0 72.0 8.0 2 5 3 12.0 149.0 74.0 12.6 3 5 4 18.0 313.0 62.0 11.5 4 5 5 NaN NaN 56.0 14.3 7.4.6 Chaining methods This is a cool bit of code, not sure where it belongs but I’ll stick it here for now until I write it into proper section. # Melt ebola: ebola_melt ebola_melt = pd.melt(ebola, id_vars=[&#39;Date&#39;, &#39;Day&#39;], var_name=&#39;type_country&#39;, value_name=&#39;counts&#39;) # Create the &#39;str_split&#39; column ebola_melt[&#39;str_split&#39;] = ebola_melt.type_country.str.split(&#39;_&#39;) # Create the &#39;type&#39; column ebola_melt[&#39;type&#39;] = ebola_melt.str_split.str.get(0) # Create the &#39;country&#39; column ebola_melt[&#39;country&#39;] = ebola_melt.str_split.str.get(1) # Print the head of ebola_melt print(ebola_melt.head()) Date Day type_country counts str_split type country 0 1/5/2015 289 Cases_Guinea 2776.0 [Cases, Guinea] Cases Guinea 1 1/4/2015 288 Cases_Guinea 2775.0 [Cases, Guinea] Cases Guinea 2 1/3/2015 287 Cases_Guinea 2769.0 [Cases, Guinea] Cases Guinea 3 1/2/2015 286 Cases_Guinea NaN [Cases, Guinea] Cases Guinea 4 12/31/2014 284 Cases_Guinea 2730.0 [Cases, Guinea] Cases Guinea 7.4.7 Concatenation You can join DataFrames together using the pd.concat() function, which seems like the equivalent of R’s rbind() and cbind() functions. row_bind_df = pd.concat([df1, df2]) col_bind_df = pd.concat([df1, df2], axis=1) Similar to the dplyr bind_rows() and bind_cols() functions, it looks like it helps you out by including the union of columns (rather than just the intersection) and uses NaN to fill in missing values. 7.4.8 Joining (Merging) You can join DataFrames using the pd.merge() function. merged_df = pd.merge(left=df1, right=df2, left_on=&#39;key1&#39;, right_on=&#39;key2&#39;) 7.4.9 Types You can change the type of a column in a DataFrame using the .astype() method. df1.col1 = df1.col1.astype(&#39;category&#39;) There are also some more feature-rich conversion functions which allow you to specify how edge-cases are handled. One such function is pd.to_numeric(). df1[&#39;col1&#39;] = pd.to_numeric(df1[&#39;col1&#39;], errors=&#39;coerce&#39;) 7.4.10 Apply You can use the .apply() method to a DataFrame to apply a function to cols (axis=0) or rows (axis=1). You can also apply to a Series directly. Some examples: # Normal function applied to a Series def recode_col1(value) : # this function does nothing return value df1[&#39;col1_recode&#39;] = df1.col1.apply(recode_col1) # Lambda function applied to a series (basically removes dollar signs) d1[&#39;col1_re&#39;] = df[&#39;col1&#39;].apply(lambda x: re.findall(&#39;\\d+\\.\\d+&#39;, x)[0]) 7.4.11 Duplicates Pandas DataFrames have a .drop_duplicates() method which you can apply to a DataFrame to remove duplicates. "],
["visualisation.html", "8 Visualisation 8.1 Matplotlib 8.2 Line Plot 8.3 Scatter Plot 8.4 Text 8.5 Histograms 8.6 Modifiers", " 8 Visualisation Visualisation in Python is a bit of a mixed bag, with techniques ranging all the way from “just as bad as base R” to “could one day get close to ggplot2”. 8.1 Matplotlib matplotlib has a sub-package called pyplot, and you will conventionally import this package as plt. import matplotlib.pyplot as plt When building plots with Matplotlib, you need to explicitly call plt.show() to print the plot to the console. If you want to clear the plot and start again you can use plt.clf(). 8.2 Line Plot For a simple line plot, you can use plt.plot(x, y) where x and y are the arrays/lists corresponding to the data points for the x and y axes. import matplotlib.pyplot as plt x_val = [0,1,2,3,4,5,6,7,8] y_val = [0,1,4,9,16,25,36,49,64] plt.plot(x_val, y_val) plt.show() 8.3 Scatter Plot Scatter plots are basically the same syntax as line plots, but with use the method plt.scatter(). import matplotlib.pyplot as plt x_val = [0,1,2,3,4,5,6,7,8] y_val = [0,1,4,9,16,25,36,49,64] plt.scatter(x_val, y_val) plt.show() Additional arguments include: s which gives the size of each point c which gives the colour of each point alpha which gives the opacity of each point 8.4 Text You can add text to plots using the plt.text() function. import matplotlib.pyplot as plt x_val = [0,1,2,3,4,5,6,7,8] y_val = [0,1,4,9,16,25,36,49,64] plt.scatter(x_val, y_val) plt.text(0, 30, &quot;Hello World!&quot;) plt.show() 8.5 Histograms Histograms are fairly straight-forward too: plt.hist(x, bins). import matplotlib.pyplot as plt x = [0,1,2,3,4,5,6,7,8,9,16,25,36,49,64] plt.hist(x, 5) plt.show() 8.6 Modifiers 8.6.1 Scales plt.xscale('log') converts the x scale to a logarithmic scale plt.yscale('log') plt.grid(True) displays the grid on the plot plt.yticks([0,1,2,3], [&quot;0&quot;, &quot;1B&quot;, &quot;2B&quot;, &quot;3B&quot;]) sets the Y axis ticks to the values given in the first argument, and sets the displayed strings on those ticks based on the second argument plt.xticks([1000, 10000, 100000], ['1k', '10k', '100k']) 8.6.2 Labels plt.xlabel('Year') sets the X axis label to “Year” plt.ylabel('Population') plt.title('World Population Projections') sets the title of the plot "],
["text-1.html", "9 Text 9.1 Regular Expressions (regex)", " 9 Text 9.1 Regular Expressions (regex) Regular Expressions are provided by the re package, which is bundled with most Python distributions. To use this package, you need to “compile” your regex using the re.compile() function then calling the methods from the returned object. # Import the regular expression module import re # Compile the pattern: prog prog = re.compile(&#39;\\d{3}-\\d{3}-\\d{4}&#39;) # See if the pattern matches result = prog.match(&#39;123-456-7890&#39;) print(bool(result)) # See if the pattern matches ## True result2 = prog.match(&#39;1123-456-7890&#39;) print(bool(result2)) ## False You can also pass the pattern into re.match() directly, but it seems like this compilation thing will be useful later on. "]
]
